# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BKdEW43jbmUj9e-DmnWPgpK86X2VLt-Y
"""

from sklearn import datasets
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import seaborn as sns
import numpy as np

X = np.array ([
  [2,1],
  [3,5],
  [4,3],
  [5,6],
  [6,7],
  [7,8]
])

n = len(X)
print ("Input data")
print(X)

mu_x= np.sum(X[:,0])/n
mu_y= np.sum(X[:,1])/n
mu= np.array([mu_x,mu_y])

print(f"\n mean")
print(f"[{mu_x},{mu_y}]")

X_centered = X - mu
print("\nCentered Data (X_std)")
print(X_centered)

Cov_matrix = np.dot(X_centered.T, X_centered) / n
print("\nCovariance Matrix (C)")
print(Cov_matrix)

a = Cov_matrix[0, 0]
d = Cov_matrix[1, 1]
b = Cov_matrix[0, 1]
trace = a + d
det = (a * d) - (b * b)

delta = np.sqrt(trace**2 - 4*det)
lambda1 = (trace + delta) / 2
lambda2 = (trace - delta) / 2

max_lambda = max(lambda1, lambda2)

denom = a - max_lambda
numerator = -b * 1
x1_val = numerator / denom
x2_val = 1.0

eigenvector = np.array([x1_val, x2_val])

print("\nEigenvector (w) ")
print(f"Calculated: {eigenvector}")
print(f"Notes used: [0.69, 1.0]")

transformed_data = np.dot(X_centered, eigenvector)
print("\nFinal Transformed Data (PC1 Projection)")
for i, val in enumerate(transformed_data):
    print(f"Point {i+1}: {val:.3f}")

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 2))
plt.scatter(transformed_data, np.zeros_like(transformed_data), color='red', marker='x')
plt.title("1D Representation (Step 6)")
plt.yticks([])
plt.axhline(0, color='black', linewidth=0.5)
for i, val in enumerate(transformed_data):
    plt.text(val, 0.02, f"{val:.2f}", ha='center', rotation=45)
plt.show()